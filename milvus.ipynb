{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define connection parameters for your cloud Milvus instance\n",
    "URI = \"XXXXXXXXXXXX\"  # Replace with your cloud Milvus connection URI\n",
    "API_KEY = \"XXXXXXXXXXXXXXX\"  # Replace with your cloud Milvus API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"XXXXXX.csv\" # replace with your file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_name) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from towhee.types.image import Image\n",
    "\n",
    "id_img = df.set_index('id')['path'].to_dict()\n",
    "def read_images(results):\n",
    "    imgs = []\n",
    "    for re in results:\n",
    "        path = id_img[re.id]\n",
    "        imgs.append(Image(cv2.imread(path), 'BGR'))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "def create_milvus_collection(collection_name, dim):\n",
    "    # connections.connect(host='127.0.0.1', port='19530')\n",
    "\n",
    "    connections.connect(uri=URI, token=API_KEY, secure=True)\n",
    "\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='text image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":512}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection\n",
    "\n",
    "collection = create_milvus_collection('text_image_search', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee import ops, pipe, DataCollection\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    pipe.input('path')\n",
    "    .map('path', 'img', ops.image_decode.cv2('rgb'))\n",
    "    .map('img', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .output('img', 'vec')\n",
    ")\n",
    "\n",
    "DataCollection(p('image.png')).show() # replace image.png with any test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = (\n",
    "    pipe.input('text')\n",
    "    .map('text', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .output('text', 'vec')\n",
    ")\n",
    "\n",
    "DataCollection(p2(\"A teddybear on a skateboard in Times Square.\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "collection = create_milvus_collection('text_image_search', 512)\n",
    "from pymilvus import connections\n",
    "\n",
    "# Use the URI and API key to establish the Milvus connection\n",
    "connections.connect(uri=URI, token = API_KEY)\n",
    "def read_csv(csv_path, encoding='utf-8-sig'):\n",
    "    import csv\n",
    "    with open(csv_path, 'r', encoding=encoding) as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield int(line['id']), line['path']\n",
    "\n",
    "p3 = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('id', 'path'), read_csv)\n",
    "    .map('path', 'img', ops.image_decode.cv2('rgb'))\n",
    "    .map('img', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device=0))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map(('id', 'vec'), (), ops.ann_insert.milvus_client(uri=URI, token=API_KEY,collection_name='text_image_search'))\n",
    "    .output()\n",
    ")\n",
    "\n",
    "ret = p3(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.load()\n",
    "print('Total number of inserted data is {}.'.format(collection.num_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def read_image(image_ids):\n",
    "    df = pd.read_csv(file_name)\n",
    "    id_img = df.set_index('id')['path'].to_dict()\n",
    "    imgs = []\n",
    "    decode = ops.image_decode.cv2('rgb')\n",
    "    for image_id in image_ids:\n",
    "        path = id_img[image_id]\n",
    "        imgs.append(decode(path))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "p4 = (\n",
    "    pipe.input('text')\n",
    "    .map('text', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map('vec', 'result', ops.ann_search.milvus_client(uri=URI, token= API_KEY, collection_name='text_image_search', limit=5))\n",
    "    .map('result', 'image_ids', lambda x: [item[0] for item in x])\n",
    "    .map('image_ids', 'images', read_image)\n",
    "    .output('text', 'images')\n",
    ")\n",
    "\n",
    "DataCollection(p4(\"book\")).show()\n",
    "DataCollection(p4(\"A black dog\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pipeline = (\n",
    "    pipe.input('text')\n",
    "    .map('text', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map('vec', 'result', ops.ann_search.milvus_client(uri=URI, token= API_KEY, collection_name='text_image_search', limit=5))\n",
    "    .map('result', 'image_ids', lambda x: [item[0] for item in x])\n",
    "    .output('image_ids')\n",
    ")\n",
    "\n",
    "def search(text):\n",
    "    df = pd.read_csv(file_name)\n",
    "    id_img = df.set_index('id')['path'].to_dict()\n",
    "    imgs = []\n",
    "    image_ids = search_pipeline(text).to_list()[0][0]\n",
    "    return [id_img[image_id] for image_id in image_ids]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "output_images = [gr.Image(type=\"filepath\") for _ in range(5)]\n",
    "interface = gr.Interface(fn=search, inputs=\"text\", outputs=output_images)\n",
    "\n",
    "interface.launch(inline=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
